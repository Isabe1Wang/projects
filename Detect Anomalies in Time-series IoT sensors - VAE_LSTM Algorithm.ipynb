{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Common"
      ],
      "metadata": {
        "id": "2muLGGu2pfuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import (accuracy_score, classification_report, confusion_matrix)\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4d9cIoPpff2",
        "outputId": "fd36567b-d000-4fc9-a6e0-fba571e25fd5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data import & preprocessing"
      ],
      "metadata": {
        "id": "fV1ZpK5tp6jk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_with_attack = pd.read_csv('gdrive/MyDrive/COMP DATA5703/SWAT_with_attack_cleaning_sampling.csv')\n",
        "data_with_attack.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "bWSrBv1eqBx7",
        "outputId": "7dd7a846-09b4-4837-eb3f-1526c2a6c5e4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Row  Class  P203  MV101    AIT203    AIT202    FIT301   AIT401    PIT502  \\\n",
              "0   30      1     2      2  328.6337  8.390669  2.212215  148.808  1.649953   \n",
              "1   60      1     2      2  328.5055  8.391951  2.207347  148.808  1.649953   \n",
              "2   90      1     2      2  328.4286  8.391951  2.209653  148.808  1.569859   \n",
              "3  120      1     2      2  328.4286  8.391630  2.212600  148.808  1.665972   \n",
              "4  150      1     2      2  328.1210  8.391630  2.208756  148.808  1.665972   \n",
              "\n",
              "     FIT501  ...    FIT101   DPIT301    FIT504    LIT401    AIT501    FIT601  \\\n",
              "0  1.727250  ...  2.527624  19.68756  0.306569  946.2958  7.878621  0.000128   \n",
              "1  1.726609  ...  2.649329  19.70677  0.306569  946.1036  7.878621  0.000128   \n",
              "2  1.727378  ...  2.620824  19.60433  0.306505  950.5255  7.878621  0.000128   \n",
              "3  1.725327  ...  2.586875  19.65555  0.308426  954.1015  7.877019  0.000128   \n",
              "4  1.727890  ...  2.542677  19.73558  0.308939  955.5242  7.877660  0.000128   \n",
              "\n",
              "     LIT301  P102    FIT201    FIT401  \n",
              "0  957.6071     1  2.439881  1.717361  \n",
              "1  959.7299     1  2.442700  1.719924  \n",
              "2  959.5697     1  2.444751  1.719924  \n",
              "3  961.0116     1  2.440137  1.716849  \n",
              "4  963.6151     1  2.440393  1.717233  \n",
              "\n",
              "[5 rows x 33 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-69287021-2566-473c-a8e5-ddb5027f203b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Row</th>\n",
              "      <th>Class</th>\n",
              "      <th>P203</th>\n",
              "      <th>MV101</th>\n",
              "      <th>AIT203</th>\n",
              "      <th>AIT202</th>\n",
              "      <th>FIT301</th>\n",
              "      <th>AIT401</th>\n",
              "      <th>PIT502</th>\n",
              "      <th>FIT501</th>\n",
              "      <th>...</th>\n",
              "      <th>FIT101</th>\n",
              "      <th>DPIT301</th>\n",
              "      <th>FIT504</th>\n",
              "      <th>LIT401</th>\n",
              "      <th>AIT501</th>\n",
              "      <th>FIT601</th>\n",
              "      <th>LIT301</th>\n",
              "      <th>P102</th>\n",
              "      <th>FIT201</th>\n",
              "      <th>FIT401</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>328.6337</td>\n",
              "      <td>8.390669</td>\n",
              "      <td>2.212215</td>\n",
              "      <td>148.808</td>\n",
              "      <td>1.649953</td>\n",
              "      <td>1.727250</td>\n",
              "      <td>...</td>\n",
              "      <td>2.527624</td>\n",
              "      <td>19.68756</td>\n",
              "      <td>0.306569</td>\n",
              "      <td>946.2958</td>\n",
              "      <td>7.878621</td>\n",
              "      <td>0.000128</td>\n",
              "      <td>957.6071</td>\n",
              "      <td>1</td>\n",
              "      <td>2.439881</td>\n",
              "      <td>1.717361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>328.5055</td>\n",
              "      <td>8.391951</td>\n",
              "      <td>2.207347</td>\n",
              "      <td>148.808</td>\n",
              "      <td>1.649953</td>\n",
              "      <td>1.726609</td>\n",
              "      <td>...</td>\n",
              "      <td>2.649329</td>\n",
              "      <td>19.70677</td>\n",
              "      <td>0.306569</td>\n",
              "      <td>946.1036</td>\n",
              "      <td>7.878621</td>\n",
              "      <td>0.000128</td>\n",
              "      <td>959.7299</td>\n",
              "      <td>1</td>\n",
              "      <td>2.442700</td>\n",
              "      <td>1.719924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>90</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>328.4286</td>\n",
              "      <td>8.391951</td>\n",
              "      <td>2.209653</td>\n",
              "      <td>148.808</td>\n",
              "      <td>1.569859</td>\n",
              "      <td>1.727378</td>\n",
              "      <td>...</td>\n",
              "      <td>2.620824</td>\n",
              "      <td>19.60433</td>\n",
              "      <td>0.306505</td>\n",
              "      <td>950.5255</td>\n",
              "      <td>7.878621</td>\n",
              "      <td>0.000128</td>\n",
              "      <td>959.5697</td>\n",
              "      <td>1</td>\n",
              "      <td>2.444751</td>\n",
              "      <td>1.719924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>120</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>328.4286</td>\n",
              "      <td>8.391630</td>\n",
              "      <td>2.212600</td>\n",
              "      <td>148.808</td>\n",
              "      <td>1.665972</td>\n",
              "      <td>1.725327</td>\n",
              "      <td>...</td>\n",
              "      <td>2.586875</td>\n",
              "      <td>19.65555</td>\n",
              "      <td>0.308426</td>\n",
              "      <td>954.1015</td>\n",
              "      <td>7.877019</td>\n",
              "      <td>0.000128</td>\n",
              "      <td>961.0116</td>\n",
              "      <td>1</td>\n",
              "      <td>2.440137</td>\n",
              "      <td>1.716849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>150</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>328.1210</td>\n",
              "      <td>8.391630</td>\n",
              "      <td>2.208756</td>\n",
              "      <td>148.808</td>\n",
              "      <td>1.665972</td>\n",
              "      <td>1.727890</td>\n",
              "      <td>...</td>\n",
              "      <td>2.542677</td>\n",
              "      <td>19.73558</td>\n",
              "      <td>0.308939</td>\n",
              "      <td>955.5242</td>\n",
              "      <td>7.877660</td>\n",
              "      <td>0.000128</td>\n",
              "      <td>963.6151</td>\n",
              "      <td>1</td>\n",
              "      <td>2.440393</td>\n",
              "      <td>1.717233</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 33 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69287021-2566-473c-a8e5-ddb5027f203b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-69287021-2566-473c-a8e5-ddb5027f203b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-69287021-2566-473c-a8e5-ddb5027f203b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_all_normal = pd.read_csv('gdrive/MyDrive/COMP DATA5703/SWAT_all_normal_data_cleaning_sampling.csv')\n",
        "data_all_normal.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "joAcxGfaqDZO",
        "outputId": "3a6ca9af-dc8d-4762-904e-7849e8d82609"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Row  Class  P203  MV101    AIT203    AIT202    FIT301  AIT401  PIT502  \\\n",
              "0   30      1     1      1  312.9198  8.313766  0.000256     0.0     0.0   \n",
              "1   60      1     1      1  313.1761  8.310242  0.000256     0.0     0.0   \n",
              "2   90      1     1      1  313.3299  8.308319  0.000256     0.0     0.0   \n",
              "3  120      1     1      1  313.4581  8.315048  0.000256     0.0     0.0   \n",
              "4  150      1     1      1  313.5863  8.310562  0.000256     0.0     0.0   \n",
              "\n",
              "     FIT501  ...  FIT101   DPIT301  FIT504    LIT401    AIT501    FIT601  \\\n",
              "0  0.001538  ...     0.0  2.560983     0.0  133.5811  7.444758  0.000256   \n",
              "1  0.001538  ...     0.0  2.560983     0.0  132.8121  7.443476  0.000256   \n",
              "2  0.001538  ...     0.0  2.560983     0.0  133.2351  7.445399  0.000256   \n",
              "3  0.001538  ...     0.0  2.564185     0.0  132.8890  7.444758  0.000256   \n",
              "4  0.001538  ...     0.0  2.564185     0.0  132.2738  7.443476  0.000256   \n",
              "\n",
              "     LIT301  P102  FIT201  FIT401  \n",
              "0  137.8252     1     0.0     0.0  \n",
              "1  138.1056     1     0.0     0.0  \n",
              "2  137.7051     1     0.0     0.0  \n",
              "3  137.0242     1     0.0     0.0  \n",
              "4  136.4234     1     0.0     0.0  \n",
              "\n",
              "[5 rows x 33 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-005958f5-2612-464b-8c8f-c160091b879b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Row</th>\n",
              "      <th>Class</th>\n",
              "      <th>P203</th>\n",
              "      <th>MV101</th>\n",
              "      <th>AIT203</th>\n",
              "      <th>AIT202</th>\n",
              "      <th>FIT301</th>\n",
              "      <th>AIT401</th>\n",
              "      <th>PIT502</th>\n",
              "      <th>FIT501</th>\n",
              "      <th>...</th>\n",
              "      <th>FIT101</th>\n",
              "      <th>DPIT301</th>\n",
              "      <th>FIT504</th>\n",
              "      <th>LIT401</th>\n",
              "      <th>AIT501</th>\n",
              "      <th>FIT601</th>\n",
              "      <th>LIT301</th>\n",
              "      <th>P102</th>\n",
              "      <th>FIT201</th>\n",
              "      <th>FIT401</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>312.9198</td>\n",
              "      <td>8.313766</td>\n",
              "      <td>0.000256</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001538</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.560983</td>\n",
              "      <td>0.0</td>\n",
              "      <td>133.5811</td>\n",
              "      <td>7.444758</td>\n",
              "      <td>0.000256</td>\n",
              "      <td>137.8252</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>313.1761</td>\n",
              "      <td>8.310242</td>\n",
              "      <td>0.000256</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001538</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.560983</td>\n",
              "      <td>0.0</td>\n",
              "      <td>132.8121</td>\n",
              "      <td>7.443476</td>\n",
              "      <td>0.000256</td>\n",
              "      <td>138.1056</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>90</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>313.3299</td>\n",
              "      <td>8.308319</td>\n",
              "      <td>0.000256</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001538</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.560983</td>\n",
              "      <td>0.0</td>\n",
              "      <td>133.2351</td>\n",
              "      <td>7.445399</td>\n",
              "      <td>0.000256</td>\n",
              "      <td>137.7051</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>120</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>313.4581</td>\n",
              "      <td>8.315048</td>\n",
              "      <td>0.000256</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001538</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.564185</td>\n",
              "      <td>0.0</td>\n",
              "      <td>132.8890</td>\n",
              "      <td>7.444758</td>\n",
              "      <td>0.000256</td>\n",
              "      <td>137.0242</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>150</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>313.5863</td>\n",
              "      <td>8.310562</td>\n",
              "      <td>0.000256</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001538</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.564185</td>\n",
              "      <td>0.0</td>\n",
              "      <td>132.2738</td>\n",
              "      <td>7.443476</td>\n",
              "      <td>0.000256</td>\n",
              "      <td>136.4234</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 33 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-005958f5-2612-464b-8c8f-c160091b879b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-005958f5-2612-464b-8c8f-c160091b879b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-005958f5-2612-464b-8c8f-c160091b879b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_with_attack.shape, data_all_normal.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idK8OKQVqEyz",
        "outputId": "ab3e6f0d-eae2-4c45-e9e1-4b92368bb7c5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((13862, 33), (16500, 33))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_with_attack.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "RxjO6uU-35lD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PCA** does not work well:\n",
        "1.   The proportion of abnormal data is small\n",
        "2.   Unimportant features have high variance\n",
        "**LDA Test here:**"
      ],
      "metadata": {
        "id": "GDC8Ih3-qOAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "X_test = data_with_attack.iloc[:, 1:-1].to_numpy().astype(np.float32) # with attack\n",
        "Y_test = data_with_attack['Class'].to_numpy().astype(np.float32)\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "lda.fit(X_test, Y_test)\n",
        "X_test = lda.transform(X_test)\n",
        "plt.scatter(X_test[:, 0], Y_test, marker='o', c=Y_test)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "jDIyKklGqMSR",
        "outputId": "cdb39e14-3a0d-4255-94da-ed1f138c0c60"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale and PCA/LDA\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "X_test = data_with_attack.iloc[:, 1:-1].to_numpy().astype(np.float32) # with attack\n",
        "Y_test = data_with_attack['Class'].to_numpy().astype(np.float32)\n",
        "X_train = data_all_normal.iloc[:, 1:-1].to_numpy().astype(np.float32) # all normal\n",
        "\"\"\"\n",
        "# Because abnormal data is few, we should increase the proportion of abnormal data before PCA to contain the feature of abnormal data\n",
        "X_attack = data_with_attack[data_with_attack['Class'] == -1].iloc[:, 1:-1].to_numpy().astype(np.float32) # only attack\n",
        "# increase attack data\n",
        "X_alter_for_PCA = X_attack\n",
        "for i in range(20):\n",
        "  X_alter_for_PCA = np.concatenate((X_alter_for_PCA, X_attack))\n",
        "\n",
        "pca = PCA(n_components=.99).fit(np.concatenate((X_train, X_test, X_alter_for_PCA)))\n",
        "X_test = pca.transform(X_test)\n",
        "X_train = pca.transform(X_train)\n",
        "\"\"\"\n",
        "\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "lda.fit(X_test, Y_test)\n",
        "X_test = lda.transform(X_test)\n",
        "X_train = lda.transform(X_train)\n",
        "\n",
        "# Pre-process\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "scaler1 = StandardScaler()\n",
        "\n",
        "scaler1.fit(np.concatenate((X_train, X_test)))\n",
        "X_train = scaler1.transform(X_train)\n",
        "X_test = scaler1.transform(X_test)\n",
        "scaler.fit(np.concatenate((X_train, X_test)))\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAwZ07w_qST-",
        "outputId": "999e8c8b-7364-4d84-95b4-905316368811"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((16500, 1), (13862, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_with_attack_lda = pd.DataFrame(X_test)\n",
        "data_with_attack_lda['Class'] = data_with_attack['Class']\n",
        "\n",
        "data_all_normal_lda = pd.DataFrame(X_train)\n",
        "data_all_normal_lda['Class'] = data_all_normal['Class']"
      ],
      "metadata": {
        "id": "cdMpS7fpqXO3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_with_attack_lda.isna().sum(), data_all_normal_lda.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYI3Xgiyqbi0",
        "outputId": "bee8068f-82c2-4a8b-fb06-7f6fc6093de2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0        0\n",
              " Class    0\n",
              " dtype: int64, 0        0\n",
              " Class    0\n",
              " dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_with_attack_lda.shape, data_all_normal_lda.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAAF29NL3fC1",
        "outputId": "920aec11-63a4-49ad-c695-3dbdab1e5559"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((13862, 2), (16500, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VAE-LSTM"
      ],
      "metadata": {
        "id": "eZ6SMDBC_2VQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Data_Process(object):\n",
        "\n",
        "    def __init__(self,dataset,columns,time_steps):\n",
        "        self.time_steps = time_steps\n",
        "        self.data = dataset\n",
        "        self.columns = columns\n",
        "        self.data[self.columns] = self.data[self.columns].shift(-1) - self.data[self.columns]\n",
        "        self.data = self.data.dropna(how='any')\n",
        "        self.pt= 0\n",
        "        self.all_data = np.array([])\n",
        "        self.labels = np.array([])\n",
        "        \n",
        "    def _process_data(self, is_smote=False):\n",
        "        self._data_arrange(is_smote)\n",
        "\n",
        "    def _data_arrange(self, is_smote=False):\n",
        "        array_length = self.data.shape[0]-self.time_steps+1\n",
        "        self.all_data = np.zeros(shape=(array_length, self.time_steps, len(self.columns)))\n",
        "        self.labels = np.zeros(shape=(array_length))\n",
        "        column_array = self.data[self.columns].values  \n",
        "        label_array = self.data['Class'].values\n",
        "        for i in range(array_length):\n",
        "            column_array_reshape = column_array[i:i+self.time_steps].reshape((-1,self.time_steps,len(self.columns)))\n",
        "            timesteps_label = label_array[i:i+self.time_steps]\n",
        "            # print(self.labels.shape)\n",
        "            label_reshape = timesteps_label[-1]\n",
        "            self.all_data[i] = column_array_reshape\n",
        "            self.labels[i] = label_reshape \n",
        "        # after arraging time_step data, we can shffule or smote here to avoid loss -> inf by unbalance features\n",
        "        if is_smote:\n",
        "            smote = SMOTE()\n",
        "            all_data_for_remote = self.all_data.reshape(-1,self.time_steps*len(self.columns))\n",
        "            all_data_for_remote,self.labels = smote.fit_resample(all_data_for_remote,self.labels)\n",
        "            self.all_data = all_data_for_remote.reshape(-1,self.time_steps,len(self.columns))\n",
        "        rng_state = np.random.get_state()\n",
        "        np.random.shuffle(self.all_data)\n",
        "        np.random.set_state(rng_state)\n",
        "        np.random.shuffle(self.labels)\n",
        "\n",
        "    def retrive_data(self,batch_size):\n",
        "        batch_train = None\n",
        "        if self.all_data.shape[0] < batch_size:\n",
        "            batch_train = self.all_data\n",
        "        else:\n",
        "            if (self.pt + 1) * batch_size >= self.all_data.shape[0]:\n",
        "                self.pt = 0\n",
        "                batch_train = self.all_data[self.pt * batch_size:,]\n",
        "            else:\n",
        "                batch_train = self.all_data[self.pt * batch_size:(self.pt + 1) * batch_size,]\n",
        "                self.pt = self.pt + 1\n",
        "        if batch_train.ndim < self.all_data.ndim:\n",
        "            batch_trainn = np.expand_dims(batch_train,0)\n",
        "        return batch_train\n",
        "\n",
        "#data_source_all_normal_class = Data_Process(data_all_normal_pca, column_names, time_steps=32)\n",
        "#data_source_all_normal_class._process_data()\n",
        "#data_source_all_normal_class.retrive_data(128).shape"
      ],
      "metadata": {
        "id": "ET41epLrqg28"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def leak_relu(x, leak=0.2, name='leak_relu'):\n",
        "\treturn tf.maximum(x, leak*x)\n",
        "\n",
        "\n",
        "def get_lstm_cell(unit_list, act_fn_list):\n",
        "    return tf.keras.layers.StackedRNNCells([tf.keras.layers.LSTMCell(unit, activation=act_fn) for unit,act_fn in zip(unit_list,act_fn_list)])"
      ],
      "metadata": {
        "id": "RhOZSaJ925OV"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_names = list(data_with_attack_lda.columns)\n",
        "column_names.remove('Class')"
      ],
      "metadata": {
        "id": "BhO-CfEYqkfN"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE_LSTM(object):\n",
        "    def __init__(self, train_data, test_data, columns, z_sample_dim, time_steps, outlier_fraction, epochs, latent_dims, learning_rate=0.001):\n",
        "        tf.compat.v1.reset_default_graph()\n",
        "        self.outlier_fraction = outlier_fraction\n",
        "        self.data_train= Data_Process(train_data, columns, time_steps=time_steps)\n",
        "        self.data_train._process_data()\n",
        "        self.data_length = self.data_train.all_data.shape[0]\n",
        "        self.data_test = Data_Process(test_data, columns, time_steps=time_steps)\n",
        "        self.data_test._process_data(is_smote=True)\n",
        "        self.latent_dims = latent_dims\n",
        "        self.batch_size = 128\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        \n",
        "        self.input_dim = len(columns)\n",
        "        self.z_sample_dim = z_sample_dim\n",
        "        self.time_steps = time_steps\n",
        "    \n",
        "        self.pt = 0 \n",
        "        self.score = 0\n",
        "        self.session = tf.compat.v1.Session()\n",
        "        self._network()\n",
        "        self.session.run(tf.compat.v1.global_variables_initializer())\n",
        "\n",
        "        \n",
        "    def _network(self):\n",
        "        with tf.compat.v1.variable_scope('ph'):\n",
        "            tf.compat.v1.disable_eager_execution()\n",
        "            self.X = tf.compat.v1.placeholder(tf.float32, shape=[None,self.time_steps,self.input_dim], name='X_input')\n",
        "            # print(input_dimm, self.X.shape)\n",
        "\n",
        "        with tf.compat.v1.variable_scope('encoder'):\n",
        "            with tf.compat.v1.variable_scope('latent_mu'):\n",
        "                lstm_mu_cell_1 = get_lstm_cell([self.z_sample_dim], [leak_relu])\n",
        "                lstm_mu_cell_2 = get_lstm_cell([self.z_sample_dim], [leak_relu])\n",
        "\n",
        "                (mu_output_1, mu_output_2),_ = tf.compat.v1.nn.bidirectional_dynamic_rnn(lstm_mu_cell_1, lstm_mu_cell_2, self.X, dtype=tf.float32)\n",
        "                Z_mean = tf.add(mu_output_1, mu_output_2)\n",
        "                \n",
        "            with tf.compat.v1.variable_scope('latent_sigma'):\n",
        "                lstm_sigma_cell_1 = get_lstm_cell([self.z_sample_dim], [tf.nn.softplus])\n",
        "                lstm_sigma_cell_2 = get_lstm_cell([self.z_sample_dim], [tf.nn.softplus])\n",
        "                (sigma_output_1, sigma_output_2),_ = tf.compat.v1.nn.bidirectional_dynamic_rnn(lstm_sigma_cell_1, lstm_sigma_cell_2, self.X, dtype=tf.float32)\n",
        "                Z_log_sigma = tf.add(sigma_output_1, sigma_output_2)\n",
        "                epsilon = tf.compat.v1.random_normal(tf.shape(Z_mean), 0,1, dtype=tf.float32)\n",
        "                Z_sample = Z_mean + Z_log_sigma * epsilon\n",
        "        \n",
        "        with tf.compat.v1.variable_scope('decoder'):\n",
        "            lstm_cell = get_lstm_cell([self.latent_dims,self.input_dim], [leak_relu, leak_relu])\n",
        "            self.reconX,_ = tf.compat.v1.nn.dynamic_rnn(lstm_cell, Z_sample, dtype=tf.float32)\n",
        " \n",
        "        with tf.compat.v1.variable_scope('loss'):\n",
        "            backend_dims = np.arange(1,tf.keras.backend.ndim(self.X))\n",
        "            reconX_loss = tf.losses.mean_squared_error(self.X, self.reconX)\n",
        "            kl_loss = - 0.5 * tf.reduce_mean(1 + Z_log_sigma - tf.square(Z_mean) - tf.exp(Z_log_sigma))\n",
        "            self.loss = reconX_loss + kl_loss\n",
        "            self.vae_lstm_loss = tf.compat.v1.reduce_sum(tf.square(self.X - self.reconX), reduction_indices=backend_dims)\n",
        "          \n",
        "\n",
        "        with tf.compat.v1.variable_scope('train'):\n",
        "            self.train_optim = tf.compat.v1.train.AdamOptimizer(self.learning_rate).minimize(self.loss)\n",
        "            \n",
        "            \n",
        "    def train(self):\n",
        "        for epoch in range(self.epochs):\n",
        "            # print(math.ceil((float)(self.data_length)/self.batch_size), self.data_length, self.batch_size)\n",
        "            for i in range(math.ceil((float)(self.data_length)/self.batch_size)):\n",
        "                self.data_train.pt = 1\n",
        "                this_X = self.data_train.retrive_data(self.batch_size)\n",
        "                # print(this_X)\n",
        "                self.session.run([self.train_optim],feed_dict={self.X: this_X})\n",
        "            \n",
        "            if epoch % 10 == 9:\n",
        "                mse_loss = self.session.run([self.loss],feed_dict={self.X: self.data_train.all_data})\n",
        "                print('Epoch {}/{}: with loss: {}'.format(epoch+1, self.epochs, np.average(mse_loss)))\n",
        "        self._recon_score(self.data_train.all_data)\n",
        "    \n",
        "    def _recon_score(self,input_data):       \n",
        "        input_vae_lstm_loss = self.session.run(self.vae_lstm_loss,feed_dict={self.X: input_data})\n",
        "        self.score = np.percentile(input_vae_lstm_loss, (1-self.outlier_fraction)*100)\n",
        "       \n",
        "    def anomaly(self,test):\n",
        "        test_data_loss = self.session.run(self.vae_lstm_loss,feed_dict={self.X: test})\n",
        "        anomaly_result = map(lambda x: 1 if x< self.score else -1,test_data_loss)\n",
        "        return list(anomaly_result)\n",
        "\n",
        "    def return_labels(self):\n",
        "        return self.data_test.labels, self.anomaly(self.data_test.all_data)"
      ],
      "metadata": {
        "id": "Ztsx1wd9sha1"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Best hyperparameters"
      ],
      "metadata": {
        "id": "62g-TpmrHhwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# outlier_fraction: too small will be robust with abnormal data, too big will be refuse normal data\n",
        "VAE_LSTM_4 = VAE_LSTM(data_all_normal_lda, data_with_attack_lda, column_names, z_sample_dim=3, time_steps=64, outlier_fraction=0.01, epochs=40, latent_dims=32, learning_rate=0.001)\n",
        "print(\"Using LDA!!\")\n",
        "print(\"z_sample_dim=3, time_steps=64, outlier_fraction=0.01, epochs=40, latent_dims=32, learning_rate=0.001\")\n",
        "VAE_LSTM_4.train()\n",
        "labels_after_smote, predict_label_4 = VAE_LSTM_4.return_labels()\n",
        "print(classification_report(labels_after_smote, predict_label_4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bInKzrWKB9fd",
        "outputId": "9b2da225-c327-4bb3-98e0-190f917b90f2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using LDA!!\n",
            "z_sample_dim=3, time_steps=64, outlier_fraction=0.01, epochs=40, latent_dims=32, learning_rate=0.001\n",
            "Epoch 10/40: with loss: 0.090866319835186\n",
            "Epoch 20/40: with loss: 0.03824806958436966\n",
            "Epoch 30/40: with loss: 0.018558377400040627\n",
            "Epoch 40/40: with loss: 0.009370784275233746\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.90      0.52      0.66     13113\n",
            "         1.0       0.66      0.94      0.78     13113\n",
            "\n",
            "    accuracy                           0.73     26226\n",
            "   macro avg       0.78      0.73      0.72     26226\n",
            "weighted avg       0.78      0.73      0.72     26226\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# outlier_fraction: too small will be robust with abnormal data, too big will be refuse normal data\n",
        "VAE_LSTM_5 = VAE_LSTM(data_all_normal_lda, data_with_attack_lda, column_names, z_sample_dim=3, time_steps=64, outlier_fraction=0.01, epochs=40, latent_dims=32, learning_rate=0.001)\n",
        "print(\"Using LDA!!\")\n",
        "print(\"z_sample_dim=3, time_steps=64, outlier_fraction=0.01, epochs=40, latent_dims=32, learning_rate=0.001\")\n",
        "VAE_LSTM_5.train()\n",
        "labels_after_smote, predict_label_5 = VAE_LSTM_5.return_labels()\n",
        "print(classification_report(labels_after_smote, predict_label_5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0H6hJhUKy-xJ",
        "outputId": "78b0285e-3811-48f2-caba-35d39e8ab683"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using LDA!!\n",
            "z_sample_dim=3, time_steps=64, outlier_fraction=0.01, epochs=40, latent_dims=32, learning_rate=0.001\n",
            "Epoch 10/40: with loss: 0.0767865926027298\n",
            "Epoch 20/40: with loss: 0.03199316933751106\n",
            "Epoch 30/40: with loss: 0.015557612292468548\n",
            "Epoch 40/40: with loss: 0.008018500171601772\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.90      0.52      0.66     13111\n",
            "         1.0       0.66      0.94      0.78     13111\n",
            "\n",
            "    accuracy                           0.73     26222\n",
            "   macro avg       0.78      0.73      0.72     26222\n",
            "weighted avg       0.78      0.73      0.72     26222\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Other hyperparameters testing"
      ],
      "metadata": {
        "id": "KsJdsJdQHtcv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# outlier_fraction: too small will be robust with abnormal data, too big will be refuse normal data\n",
        "VAE_LSTM_1 = VAE_LSTM(data_all_normal_lda, data_with_attack_lda, column_names, z_sample_dim=3, time_steps=32, outlier_fraction=0.1, epochs=40, latent_dims=32, learning_rate=0.001)\n",
        "print(\"Using LDA!!\")\n",
        "print(\"z_sample_dim=3, time_steps=32, outlier_fraction=0.1, epochs=40, latent_dims=32, learning_rate=0.001\")\n",
        "VAE_LSTM_1.train()\n",
        "labels_after_smote, predict_label_1 = VAE_LSTM_1.return_labels()\n",
        "print(classification_report(labels_after_smote, predict_label_1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHA7QbyewEr1",
        "outputId": "1cc00298-68be-4f43-c624-97085d378756"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using LDA!!\n",
            "z_sample_dim=3, time_steps=32, outlier_fraction=0.1, epochs=40, latent_dims=32, learning_rate=0.001\n",
            "Epoch 10/40: with loss: 0.07244569808244705\n",
            "Epoch 20/40: with loss: 0.030086228623986244\n",
            "Epoch 30/40: with loss: 0.015052284114062786\n",
            "Epoch 40/40: with loss: 0.008308272808790207\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.83      0.49      0.61     13137\n",
            "         1.0       0.64      0.90      0.75     13137\n",
            "\n",
            "    accuracy                           0.69     26274\n",
            "   macro avg       0.73      0.69      0.68     26274\n",
            "weighted avg       0.73      0.69      0.68     26274\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# outlier_fraction: too small will be robust with abnormal data, too big will be refuse normal data\n",
        "VAE_LSTM_2 = VAE_LSTM(data_all_normal_lda, data_with_attack_lda, column_names, z_sample_dim=3, time_steps=32, outlier_fraction=0.01, epochs=40, latent_dims=32, learning_rate=0.001)\n",
        "print(\"Using LDA!!\")\n",
        "print(\"z_sample_dim=3, time_steps=32, outlier_fraction=0.01, epochs=40, latent_dims=32, learning_rate=0.001\")\n",
        "VAE_LSTM_2.train()\n",
        "labels_after_smote, predict_label_2 = VAE_LSTM_2.return_labels()\n",
        "print(classification_report(labels_after_smote, predict_label_2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgefqcfD6eQ-",
        "outputId": "1c94ca6f-8d47-49ac-8350-5c3dbe6d7d91"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using LDA!!\n",
            "z_sample_dim=3, time_steps=32, outlier_fraction=0.01, epochs=40, latent_dims=32, learning_rate=0.001\n",
            "Epoch 10/40: with loss: 0.09473664313554764\n",
            "Epoch 20/40: with loss: 0.0443907268345356\n",
            "Epoch 30/40: with loss: 0.024797240272164345\n",
            "Epoch 40/40: with loss: 0.015427250415086746\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.93      0.46      0.61     13136\n",
            "         1.0       0.64      0.96      0.77     13136\n",
            "\n",
            "    accuracy                           0.71     26272\n",
            "   macro avg       0.78      0.71      0.69     26272\n",
            "weighted avg       0.78      0.71      0.69     26272\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# outlier_fraction: too small will be robust with abnormal data, too big will be refuse normal data\n",
        "VAE_LSTM_3 = VAE_LSTM(data_all_normal_lda, data_with_attack_lda, column_names, z_sample_dim=3, time_steps=32, outlier_fraction=0.02, epochs=40, latent_dims=32, learning_rate=0.001)\n",
        "print(\"Using LDA!!\")\n",
        "print(\"z_sample_dim=3, time_steps=32, outlier_fraction=0.02, epochs=40, latent_dims=32, learning_rate=0.001\")\n",
        "VAE_LSTM_3.train()\n",
        "labels_after_smote, predict_label_3 = VAE_LSTM_3.return_labels()\n",
        "print(classification_report(labels_after_smote, predict_label_3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mP-EbgCr8JpD",
        "outputId": "4c2b633a-8855-41ba-ecd5-9f2d3889bb18"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using LDA!!\n",
            "z_sample_dim=3, time_steps=32, outlier_fraction=0.02, epochs=40, latent_dims=32, learning_rate=0.001\n",
            "Epoch 10/40: with loss: 0.10990281403064728\n",
            "Epoch 20/40: with loss: 0.057437606155872345\n",
            "Epoch 30/40: with loss: 0.037935417145490646\n",
            "Epoch 40/40: with loss: 0.02888563647866249\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.91      0.45      0.60     13135\n",
            "         1.0       0.64      0.95      0.76     13135\n",
            "\n",
            "    accuracy                           0.70     26270\n",
            "   macro avg       0.77      0.70      0.68     26270\n",
            "weighted avg       0.77      0.70      0.68     26270\n",
            "\n"
          ]
        }
      ]
    }
  ]
}